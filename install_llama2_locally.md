1. 下载llama.cpp并编译 https://github.com/ggerganov/llama.cpp
2. 下载llama2模型 Llama-2-7b-hf
3. convert to f16 guff
4. 量化(quantize)模型
5. 测试